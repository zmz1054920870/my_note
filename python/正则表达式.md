解释 \A\Z  ,  ^和$ , 还有? m  的例子

```python
import re
a = '1aaaaaaaaaaaaaaaaaaaaa2\n1bbbbbbbbbbbbbbbbbbbbb2'
print(a)
b = re.findall(r'(?sm)^1.*?2$', a)
print(b)
```



**🔺完美匹配IP的正则**

这里还有一个bug，就是当我们是以0开头的时候，他还是给他算进去了,其他的都还号

```python
import re
p = r"^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$"
a = '092.055.012.01'
re.search(p, a)
>>> <_sre.SRE_Match object; span=(0, 14), match='092.055.012.01'>

# 上面这个玩意是以前面配置开头的 对于我们场景不适用，只要把前面^去掉就行，但是还是那样会把0开头的匹配了
p = r"^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$"
a = '的292.055.012.01'
re.search(p, a)
<_sre.SRE_Match object; span=(2, 15), match='92.055.012.01'>

这个还有一个致命的弱点，就上面这个例子
```



# 一、思路（两套规则）

使用python进行正则匹配是跨语言的，所以存在两套语言规则

怎么理解呢？首先我们使用python代码写的正则表达式首先要遵循python的规则，然后我们写好的正则表达式会传递给正则解释器，这个时候他会对我们传递的数据再次进行解析

例子：

```python
import re
temp = '[' #匹配目标
patter = '[' #模板
re.search(patter, temp)
>>> unterminated character set at position 0 (位置0处的未终止字符集
)
"""
'['在python的字符串中，可以直接打印这个字符。当我们执行正则匹配的时候，传入到正则解释器中，这个时候他就不符合正则解释器的规则了，会给你报错，因为在正则解释器中'['必须和']'成对出现，组成集合。如果要匹配'['怎么办
我们要进行转义
"""

import re
temp = '[' #匹配目标
patter1 = '\\[' #模板
patter2 = '\['
patter3 = r'\['
上面三种都可以
re.search(patter1, temp)

为什么上面三种都可以？
patter1: 在python中'\\['表示 r'\[' ，然后传递给正则解释器，在正则解释器中'\'对'['进行了转义，这时的'['就不是一个集合符号了。
                                                                    
patter2: 在python中"\"起转义作用，但是用于"\" + 'E'没有特殊含义，这个时候他们代表两个字符，然后传递给正则解释器，在正则解释器中'\'对'['进行了转义，这时的'['就不是一个集合符号了。                                                                
patter3: 在python中r'\['，代表raw字符，python解释器只解释字面意思，‘\’没有转义的功能， 这个时候他们代表两个字符，然后传递给正则解释器，在正则解释器中'\'对'['进行了转义，这时的'['就不是一个集合符号了。                                                                           
```



# 二、反斜杠+字母，在[]中仍有特殊意义，其他元字符失去特殊意义

```python
import re
temp = '1A_'
patter = r'[\d]'
re.search(patter, temp)
>>> <_sre.SRE_Match object; span=(0, 1), match='1'>
```

特别注意：

反斜杠+字母（仅限于键盘上字母，ABCD，不是符号*&#），如果没有特殊含义，正则解释器中无法解释是会报错的

例子：

```python
import re
re.search(r'\m', 'ABCD')
>>> bad escape \m at position 0(在位置0处错误转义)
```

###### 有意义得转义

- \r\n\f\t\b
- \number  表示子组、八进制数对应得ASCII码字符，你直接在python中print('\065')  会打印 数字5
- \x number 表示这个十六进制数对应的ASCII码字符，你直接在python中print('\x35')  会打印 数字5
- \u    表示unicode字符



# 三、匹配unicode中文字

匹配中文字符的正则表达式： [\u4e00-\u9fa5] 

匹配所有ASCII码的正则: `[\000-\177]`   这是一个 八进制数

\u4e00解码过来是‘一’

\u9fa5解码过来是‘龥’

是 unicode 里面的中文编码的第一个字和最后一个字

```python
temp = bytes('\u4e00', 'unicode-escape')
temp.decode('unicode-escape')
>> '一'
```

评注：匹配中文还真是个头疼的事，有了这个表达式就好办了



# 四、匹配全部ASCII字符

[\000-\177]

评注：\加0或者3位数字是一个八进制数，这也是反斜杠的另外一个用法，表示的是这个八进制数对应的ASCII码字符



# 五、正则表达式中的转义必须有意义，不然报错

1. python中如果反斜杠+字母有特殊意义，那么他代表一个特殊字符，当反斜杠+字母没有特殊意义他表示两个字符
2. 正则表达式中，反斜杠+字母有特殊意义，那么他代表一个特殊字符或者特殊功能，当反斜杠+字母没有特殊意义，正则引擎会给你报错



先说结论：正则解释器也有转义功能

注意点一：'\ '+'字符'有特殊意义的时候反斜杠才起作为转移字符，这个时候反斜杠和后面的字符一起组成一个字符（可以采用len()函数进行测试），不然他就是原生字符反斜杠，这个时候反斜杠和后面的字符一共是2个字符

例子：\ + 这里代表2个字符分别是反斜杠和+，因为\和+没有特殊意义

https://blog.csdn.net/anhui5201314456/article/details/102429451

```python
要匹配字符串中1个反斜杠应该怎么写正则表达式？"\\"，这样行吗？试试就知道了，re模块抛异常了，因为在正则表达式中，"\\"就是一个反斜杠，对于正则表达式解析器来说，是一个转义字符，但是后面啥也没有，自然就报错了，"\\\"三个肯定是不行的，试试四个"\\\\"，完美匹配。

 
代码如下:
import re
re_str_patt = "\\\\"
reObj = re.compile(re_str_patt)
str_test = "abc\\cd\\hh"
print reObj.findall(str_test)

输出 ：['\\', '\\']
备注：
     1、第二行代码只使用了python非原生字符串，所以它在正则表达式中表示的是一个反斜杠。（即四合一）
     2、由于python字符串中，反斜杠表示转义，所以第四行代码中的字符串表示的是：
        abc后是 一个反斜杠 ，然后接cd，再接 一个反斜杠 ，然后是hh
     3、代码段输出的是一个列表，列表中有两个元素。每一个元素都是一个字符串(python中的字符串)，
        所以列表的第一个元素实际是表示一个反斜杠，同样，列表的第二个元素也是表示一个反斜杠。
     4、输出也可能是这样的： [r'\', r'\'] 两种输种输出效果是一致的。
 
 
代码如下改动：
 
import re
re_str_patt = r"\\\\"
reObj = re.compile(re_str_patt)
str_test = "abc\\cd\\hh"
print reObj.findall(str_test)

输出： []
备注: 1、第二行代码改成了原生字符串，此时正则表达式要匹配的则是两个连续的反斜杠。（ 即二合一）
       2、第四行代码中的字符串表示的是：abc后是 一个反斜杠 ，然后接cd，再接 一个反斜杠 ，然后是hh。
       3、所以没有匹配的内容，输出为一个空列表。
 

     对于第一段代码要这么理解，首先第一重转换是 字符串自身的转义，那么"\\\\"，实际上就是表示两个反斜杠（两个字符），然后传入 正则表达式解析器，因为反斜杠依然是转义字符，那么进行第二重转换，两个反斜杠就代表一个反斜杠，所以就能和一个反斜杠进行匹配了，那么匹配连续的两个反斜杠，写正则表达式时就要写8次"\"了，相当壮观。\d+在正则表达式里面表示匹配连续1一个以上的数字字符,可是如果想匹配： 一个反斜杠，后接字母d，再接一个加号 ，这个字符串怎么写呢？(答案："\\\\d\\+")
代码如下:

import re
re_str_patt = "\\\\d\\+"
print re_str_patt
reObj = re.compile(re_str_patt)
print reObj.findall("\\d+")
 
输出：\\d\+
      ['\\d+']

 
     写成re_str_patt = "\\\\d\+"也行，因为\+对于字符串来说，没有转义意义，所以就当成一个反斜杠了。
在python中写正则表达式时用得最多的是raw字符串，原生字符串，什么意思？就是只有一重转换了，没有字符串转换了，只在正则表达式内部进行转换了，这样匹配一个反斜杠的正则表达式可以这样写，re_str_patt = r"\\"。
 
     有人会想，以后写windows的文件路径什么的方便了，呵呵直接 path = r"c:\myforder\xx" 搞定，是的，这句没有问题，但是如果你写成 path = r"c:\myforder\xx\"，直接报错了，为什么？因为反斜杠虽然不作为转义字符了，但是还是对它后面的引号（包括单引号）有影响，使这个引号不被视为字符串的终止，以为它后面还有字符，但是实际没有，因此会报错。
 
    其实可以反过来想raw字符串里面要表示引号怎么办呢？，可以发现 path = r"\\123\"xxx" 是可以的，那用raw字符串岂不是有局限性？不过raw在设计之初就是用来支持正则表达式的，而在正则里面反斜杠是转义字符，所以不可能出现在字符串的末尾的，所以建议不要图方便在其他的地方使用raw。
```



#### \b 和 \B

```
\b 表示 字母、数字、下划线、汉字组的词 与 非 字母、数字、下划线、汉字单字符的边界
\B 表示 字母、数字、下划线、汉字组的词 与  字母、数字、下划线、汉字单字符的边界
```



# 六、ilsmux

#### iLsmux

```bash
(?i)	忽略大小写
(?L)	Local
(?m)	mutiline 和^ $配合，界定为每行的开始和结尾
(?s)	. 可以匹配所有空白字符， 以前. 只能匹配除\n换行符以外的全部字符

(?x)	可以让我们想书写代码意义书写正则表达式，可以像写代码一样添加注释，但是后面的注释不能再\后面
```



#### ?的扩展

```python
>>> a = 'abcd你好_abcd他好'
>>> p = r'(abcd)你好_(?p<data>abcd)他好'
>>> p = r'(abcd)你好_(?P<data>abcd)他好'
>>> re.search(p, a)
<_sre.SRE_Match object; span=(0, 13), match='abcd你好_abcd他好'>
>>> re.findall(p, a)
[('abcd', 'abcd')]
>>> 
分组命名
```



##### 2. （?: 表达式） 一个不保存的分组，结果中也不会显示， 正则表达式中也不能引用

```python
>>> import re
>>> 
>>> 
>>> a = 'abcd张1234'
>>> p = r'[a-z]{4}张(?:[0-9]{4})'
>>> c = re.search(p, a)
>>> c
<_sre.SRE_Match object; span=(0, 9), match='abcd张1234'>
>>> c.groups()
()
>>> 
```



##### 3. (?P<分组名>表达式) 主要跟group和groupdict配合使用进行取值

> - ​	**groupdict只对自定义命名分组有效**

```bash
>>> a = 'abcd张明柱1234abcd'
>>> p = r'(?P<name>[\u4e00-\u9fa5]{3})(?#所有汉字匹配3次)\d*'
>>> c = re.search(p, a)
>>> c
<_sre.SRE_Match object; span=(4, 11), match='张明柱1234'>
>>> c.group('name')
'张明柱'
>>> c.groups()
('张明柱',)
>>> c.groupdict()
{'name': '张明柱'}
>>> 
```



##### 4.（?(分组id或者分组name)y|x）, y和x是一个正则表达式， 如果前面的id或者name存在就用y继续进行匹配，如果不存在使用x匹配





##### 5. (?=...)	前视肯定断言， 匹配不作结果，只当判断， ...三个点表示正则

```python
import re
a = 'www.baidu.com'
p = r'baidu(?=.com)'
re.search(p, a)
>>><_sre.SRE_Match object; span=(4, 9), match='baidu'>

"""
baidu的后面必须是.com才能匹配
"""
```



##### 6. (?!...) 前视否定断言 ,同(?=...) 相反



##### 7. (?<=) 后视肯定断言

```python
import re
a = 'www.baidu.com'
p = r'(?<=baidu).com'
re.search(p, a)
<_sre.SRE_Match object; span=(9, 13), match='.com'>

"""
.com的前面必须是baidu才能匹配
"""
```



##### 8.（?<!..）同 7相反







**🔺9  ？的终极含义**

> ​	**<span style='color:red'>?</span>代表前面的正则匹配0次或者1次，0次即是说，匹配一个空字符**

```python
a='abc'
p='d?'
re.search(p, a)
>>><_sre.SRE_Match object; span=(0, 0), match=''>
```

**🔺d？组合匹配了个空字符"",代表前面的d匹配失败了,匹配了0次返回了None，不是d匹配了一个空字符哈，只有? * {m,n}才可以匹配空字符**



**10.	(?(id或者name)Y|N)**

> ​	**有了前面的？的终极含义，我们才能正确的使用**

🔺通过我们使用？ * {0, m}这样的几个数量匹配字符，我们才能来设定条件，因为有这几个的存在，所以当这个几个符号前面的分组或者正则字符无法匹配的时候，他会取0，匹配一个空字符，从而不会导致? * {m,n}修饰的正则表达式不至于是匹配失败，而是返回一个空字符



> ​	注意了，在使用**(?(id或者name)Y|N)**条件表达式的时候，分组内部经量不要出现上面几个玩意，尤其是在使用他们进行全局范围过滤的时候，不然分组里面一定能匹配成功。因为有这几个玩意存在的时候，至少返回空字符，空字符也代表匹配成功

**举例说明一下，为什么至少返回空字符**

```python
import re
a='abcde'
p=r'\d*'	
c=re.search(p,a) #代表\d匹配失败,啥也没匹配上，返回了None，*取0，代表\d不参与匹配
print(c)
>>><_sre.SRE_Match object; span=(0, 0), match=''>
# *一定不会匹配失败，至少返回空字符

a='abcde'
p=r'\d?'
c=re.search(p, a)
print(c)
>>><_sre.SRE_Match object; span=(0, 0), match=''>
# ?一定不会匹配失败，至少返回空字符

a='abcde'
p=r'\d{0,4}'
c=re.search(p, a)
>>><_sre.SRE_Match object; span=(0, 0), match=''>
# {0,m}一定不会匹配失败，至少返回空字符
```







```python
import re
a='     a'
p='^ +a'	#表示以任意空格开头其中有a的
re.search(p,a)
>>><_sre.SRE_Match object; span=(0, 6), match=''>
```





# 七、search和findall区别

**先看下面几个例子(顺便还能了解一下|管道符的作用)**



### 1. search和管道符一起使用

```python
----- 例1 -----
import re
a = 'www.baidu.com,www.gogle.cn,www.baidu.com,www.gogle.cn'
p = r'(?<=www.)\w+?(?=.com)|(?<=www.)\w+?(?=.cn)'
re.search(p,a)	
<_sre.SRE_Match object; span=(4, 9), match='baidu'>		# 当管道符前面的匹配成功以后，search就不会去执行管道符后面的正则表达式了，且一旦匹配成功一次就不会再继续进行匹配

----- 例2 -----
import re
a = 'www.baidu.com,www.gogle.cn,www.baidu.com,www.gogle.cn'
p = r'(?<=www.)\w+?(?=.cm)|(?<=www.)\w+?(?=.cn)'
re.search(p,a)	
<_sre.SRE_Match object; span=(4, 9), match='baidu'>		# 当管道符前面的匹配失败以后，search会执行管道符后面的正则表达式，且一旦匹配成功一次就不会再继续进行匹配
<_sre.SRE_Match object; span=(18, 23), match='gogle'>
```

**结论：search只要一次匹配成功以后，他就会停止正则，并放回结果**





### 2. findall和管道符一起使用

```python
----- 例1 -----
import re
a = 'www.baidu.com,www.gogle.cn,www.baidu.com,www.gogle.cn'
p = r'(?<=www.)\w+?(?=.com)|(?<=www.)\w+?(?=.cn)'
re.findall(p,a)	
['baidu', 'gogle', 'baidu', 'gogle']					# findall会匹配尽可能的匹配所有能匹配的结果，且会执行全部正则，不管前面成功与否

----- 例2 -----
import re
a = 'www.baidu.com,www.gogle.cn,www.baidu.com,www.gogle.cn'
p = r'(?<=www.)\w+?(?=.cm)|(?<=www.)\w+?(?=.cn)'
re.findall(p,a)		
['gogle', 'gogle']											# 当管道符前面的匹配失败以后，findall会继续执行管道符后面的正则表达式
```





### 3. findall和分组一起使用

先给出结论：当存在分组的时候，re.findall只会返回分组匹配的结果。如果是不被保存的分组的话，则返回全部匹配

```python
---- 匿名分组 -----
import re
>>> a = 'www.baidu.com,www.gogle.cn,www.baidu.com,www.gogle.cn'
>>> p = r'(?<=www.)b(\w+?)(?=.com)'
>>> c=re.findall(p,a)
>>> c
['aidu', 'aidu']
>>> 


----- 具名分组 ------
>>> a = 'www.baidu.com,www.gogle.cn,www.baidu.com,www.gogle.cn'
>>> p = r'(?<=www.)b(?P<百度>\w+?)(?=.com)'
>>> c = re.findall(p,a)
>>> c
['aidu', 'aidu']



----- 不被保存的分组 ----- 
>>> a = 'www.baidu.com,www.gogle.cn,www.baidu.com,www.gogle.cn'
>>> p = r'(?<=www.)b(?:\w+?)(?=.com)'
>>> c = re.findall(p,a)
>>> c
['baidu', 'baidu']

```







# 八、match和search的区别



**match**

- match必须从字符串开始的位置进行配置
- 所以使用match的时候，如果使用(?<=)很有可能会啥也匹配不到

```python
import re
a='abcd'
re.match(r'bcd',a)		# 啥也匹配不到
re.match(r'abcd',a)		# 这就能匹配到了
```



**search**

- search是在整个字符串中进行匹配







# 九、特殊字符

- \d    匹配十进制数字
- \D    匹配非十进制数字
- \w    匹配字母、数字、下划线、汉字
- \W    匹配非字母、数字、下划线、汉字
- \s     匹配除开\n\t\r\v\f 和空格 的空白字符
- \S     非空白字符
- \b     判断是否为非字母、数字、下划线、汉字，如果为非字母、数字、下划线、汉字，则判定为True
- \B     非\b
- \A\Z  字符其实位置（整个字符为准），当我们采用(?m)多行模式的时候，一般采用^和$
- \N    N为数字，代表分组的索引，引用对应分组匹配到的字符





- (?ilsmux)                             设置模式
- (?=)                                      前视断言，(?=.com)
- (?!)                                       前视否定断言
- (?<=)                                   后视断言，(?<=www.)
- (?<!)                                    后世否定断言
- (正则)                                 匿名分组，以数字代表分组，从1开始
- `(?P<name>正则)`              具名分组，以name代表分组
- (?:)                                       不被保存的分组





- *?、+?、{m,n}?、??          取消贪婪模式





# 十、分组



### 1. 不被保存的分组(?:正则表达式)







### 2. 匿名分组`()`

#### 2.1 **匿名分组的使用**

```python
import re
>>> a = 'www.baidu.com,www.gogle.cn,www.baidu.com,www.gogle.cn'
>>> p = r'(?<=www.)b(\w+?)(?=.com)'
>>> c=re.search(p,a)
>>> c
<_sre.SRE_Match object; span=(4, 9), match='baidu'>

>>> c.group()
'baidu'

>>> c.group(1)
'aidu'

>>> c.group(0)
'baidu'

>>> c.groupdict()
{}

>>> c.span()
(4, 9)

>>> c.regs
((4, 9), (5, 9))

>>> c.re
re.compile('(?<=www.)b(\\w+?)(?=.com)')

```

**备注：匿名分组，是通过index来进行分组，本地正则表示分组0，就是我们的匹配结果。其他分组从一开始算**



#### 2.2 **匿名分组在正则中的引用**

🔺在进行匿名引用的时候我们看一个错误？也不算错误，就是啥也匹配不到

```python
import re
>>>a = 'www.baidu.com,www.gogle.cn,www.baidu.com,www.gogle.cn'
>>>p = r'(?<=www.)b(\w+?)(?=.com),(?<=www.)g(\w+?)(?=.cn)'
>>>c = re.search(p,a)
>>>c
啥也没有匹配到
```

哪里错了呢？因为后视断言和前视断言只做判断，不进行匹配。其实上面的正则是要匹配 baidugogle，这怎么可能匹配得到嘛



```python
import re
>>> a = 'www.baidu.com,www.Baidu.com,www.Gogle.cn,www.gogle.cn'
>>> p = r'(?x)(www\.)b(\w+?)(\.com),\1B\2\3'
>>> c = re.search(p, a)
>>> c
<_sre.SRE_Match object; span=(0, 27), match='www.baidu.com,www.Baidu.com'>

>>> c.group()
'www.baidu.com,www.Baidu.com'

>>> c.group(0)
'www.baidu.com,www.Baidu.com'

>>> c.group(1)
'www.'

>>> c.group(2)
'aidu'

>>> c.group(3)
'.com'

>>> c.groups()
('www.', 'aidu', '.com')

>>> c.groupdict()
{}

>>> c.regs
((0, 27), (0, 4), (5, 9), (9, 13))
```

通过反斜杠+分组号进行索引





### 3. 具名分组`(?P<name>正则表达式)`

#### 3.1 具名分组的使用

```python
import re
>>> a = 'www.baidu.com,www.gogle.cn,www.baidu.com,www.gogle.cn'
>>> p = r'(?<=www.)b(?P<百度>\w+?)(?=.com)'
>>> c=re.search(p,a)
>>> c
<_sre.SRE_Match object; span=(4, 9), match='baidu'>

>>> c.group()
'baidu'

>>> c.groups()
('aidu',)

>>> c.groupdict()
{'百度': 'aidu'}

>>> c.regs
((4, 9), (5, 9))
```

#### 3.2 具名分组的引用

先给出结论：具名挂载以后，他还是具有匿名index，我们引用的时候，可以使用\number 或者 (?P=name)这两种方式进行引用，请看下面例子

```python
---------使用\num的方式进行引用------------
import re
>>> a = 'www.baidu.com,www.Baidu.com,www.Gogle.cn,www.gogle.cn'
>>> p = r'(?x)(www\.)b(\w+?)(?P<百度>\.com),\1B\2\3'
>>> c=re.search(p,a)
>>> c
<_sre.SRE_Match object; span=(0, 27), match='www.baidu.com,www.Baidu.com'>


---------使用(?P=百度)的方式进行引用------------
>>> p = r'(?x)(www\.)b(\w+?)(?P<百度>\.com),\1B\2(?P=百度)'
>>> c=re.search(p,a)
>>> c
<_sre.SRE_Match object; span=(0, 27), match='www.baidu.com,www.Baidu.com'>


>>> c.group()
'www.baidu.com,www.Baidu.com'

>>> c.groups()
('www.', 'aidu', '.com')

>>> c.groupdict()
{'百度': '.com'}


>>> c.regs
((0, 27), (0, 4), (5, 9), (9, 13))

```





# 十一、complie 编译



```python
import re
>>> a = 'www.baidu.com,www.Baidu.com,www.Gogle.cn,www.gogle.cn'
>>> p = r'(?x)(www\.)b(\w+?)(?P<百度>\.com),\1B\2\3'
>>> b = re.compile(p)
>>> c = b.search(a)

>>> c.group()
'www.baidu.com,www.Baidu.com'

>>> c.group(0)
'www.baidu.com,www.Baidu.com'

>>> c.group(1)
'www.'

>>> c.group(2)
'aidu'

>>> c.group(3)
'.com'

>>> c.groups()
('www.', 'aidu', '.com')

>>> c.groupdict()
{'百度': '.com'}
```





# 十二、finditer

根findall很像，但是又不像，他返回的是一个迭代对象，迭代对象中每一个元素都是一个匹配对象，匹配对象就有group 、groups、groupdict等方法。。更像是search 和 findall的结合体。 search只要匹配成功一次就停止匹配，但是finditer会像findall一样，匹配所有。但是他又比findall多了一点，那就是他返回的是匹配对象，不像findall一样如果存在分组的话，只返回分组匹配的内容。所以我说finditer是findall和search的结合体及完整体态。就很nice

```python
import re
>>> a = 'www.baidu.com,www.Baidu.com,www.Gogle.cn,www.gogle.cn'
>>> p = r'(?x)(www\.)b(\w+?)(?P<百度>\.com),\1B\2\3'
>>> c = re.finditer(p, a)
>>> for i in c:
	i.group()
	i.group(1)
	i.group(2)
	i.group(3)
	i.groups()
	i.groupdict()

	
'www.baidu.com,www.Baidu.com'
'www.'
'aidu'
'.com'
('www.', 'aidu', '.com')
{'百度': '.com'}




----- 这个finditer 和 search的区别 -----

>>> a = 'www.baidu.com,www.gogle.cn,www.Baidu.com,www.gogle.cn'
>>> p = r'(?<=www.)[bB](\w+?)(?=.com)'								 
>>> for i in re.finditer(p,a):												# 跟findall一样，匹配多次
	i.group()
	i.group(1)
	i.groups()
	i.groupdict()

	
'baidu'
'aidu'
('aidu',)
{}
'Baidu'
'aidu'
('aidu',)
{}


>>> re.search(p,a)															# 匹配成功一次就返回，并停止匹配
<_sre.SRE_Match object; span=(4, 9), match='baidu'>
```



# 十三、split 分割

根据正则进行分割，将字符串分割成列表返回。

**例子：以.baidu.或者.Baidu.进行分组**

```python
------------  常规匹配，证明我们的正则是没有写错的 ------
import re
>>> a = 'www.baidu.com,www.gogle.cn,www.Baidu.com,www.gogle.cn'
>>> p = r'\.(?P<百度>[bB])aidu\.'
>>> for i in re.finditer(p,a):
	i.group()
	i.group(1)
	i.groupdict()

	
'.baidu.'
'b'
{'百度': 'b'}

'.Baidu.'
'B'
{'百度': 'B'}

------------ split的正则中存在不保存的分组 --------
import re
>>> a = m = 'www.baidu.com,www.gogle.cn,www.Baidu.com,www.gogle.cn'
>>> p = r'\.(?:[bB])aidu\.'
>>> re.split(p,a)
['www', 'com,www.gogle.cn,www', 'com,www.gogle.cn']
-- 是可以返回预期结果的


------------ split的正则中存在具名分组 --------
import re
>>> a = m = 'www.baidu.com,www.gogle.cn,www.Baidu.com,www.gogle.cn'
>>> p = r'\.(?P<百度>[bB])aidu\.'
>>> re.split(p,a)
['www', 'b', 'com,www.gogle.cn,www', 'B', 'com,www.gogle.cn']
-- 问题来了，多了具名分组中的匹配结果

------------ split的正则中存在多个具名分组 --------
import re
a = m = 'www.baidu.com,www.gogle.cn,www.Baidu.com,www.gogle.cn'
p = r'(?P<张>a)i(?P<名>d)'
re.findall(p, a)
>>>[('a', 'd'), ('a', 'd')]

re.split(p, a)
>>>['www.b', 'a', 'd', 'u.com,www.gogle.cn,www.B', 'a', 'd', 'u.com,www.gogle.cn']

```

**结论：split采用的是findall进行匹配，在分割的。如果不存在分组的话，就是普通的分割。如果存在具名和匿名分组，那么他会将分组中匹配到的结果来补充切割符。所以啊，我们以后使用这个命令的时候，还是不要使用分组为妙。毕竟我们切割一般也不会写很复杂的正则，所以就不存在说要使用分组了**

